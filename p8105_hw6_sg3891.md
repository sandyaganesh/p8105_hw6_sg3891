p8105\_hw6\_sg3891
================
Sandya Ganesh
2021-12-04

## Question 1

#### Load and clean the birthweight data for regression analyses.

``` r
birthweight = 
  read_csv("./data/birthweight.csv")

skimr::skim(birthweight)
```

|                                                  |             |
|:-------------------------------------------------|:------------|
| Name                                             | birthweight |
| Number of rows                                   | 4342        |
| Number of columns                                | 20          |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |             |
| Column type frequency:                           |             |
| numeric                                          | 20          |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |             |
| Group variables                                  | None        |

Data summary

**Variable type: numeric**

| skim\_variable | n\_missing | complete\_rate |    mean |     sd |     p0 |     p25 |     p50 |     p75 |   p100 | hist  |
|:---------------|-----------:|---------------:|--------:|-------:|-------:|--------:|--------:|--------:|-------:|:------|
| babysex        |          0 |              1 |    1.49 |   0.50 |   1.00 |    1.00 |    1.00 |    2.00 |    2.0 | ▇▁▁▁▇ |
| bhead          |          0 |              1 |   33.65 |   1.62 |  21.00 |   33.00 |   34.00 |   35.00 |   41.0 | ▁▁▆▇▁ |
| blength        |          0 |              1 |   49.75 |   2.72 |  20.00 |   48.00 |   50.00 |   51.00 |   63.0 | ▁▁▁▇▁ |
| bwt            |          0 |              1 | 3114.40 | 512.15 | 595.00 | 2807.00 | 3132.50 | 3459.00 | 4791.0 | ▁▁▇▇▁ |
| delwt          |          0 |              1 |  145.57 |  22.21 |  86.00 |  131.00 |  143.00 |  157.00 |  334.0 | ▅▇▁▁▁ |
| fincome        |          0 |              1 |   44.11 |  25.98 |   0.00 |   25.00 |   35.00 |   65.00 |   96.0 | ▃▇▅▂▃ |
| frace          |          0 |              1 |    1.66 |   0.85 |   1.00 |    1.00 |    2.00 |    2.00 |    8.0 | ▇▁▁▁▁ |
| gaweeks        |          0 |              1 |   39.43 |   3.15 |  17.70 |   38.30 |   39.90 |   41.10 |   51.3 | ▁▁▂▇▁ |
| malform        |          0 |              1 |    0.00 |   0.06 |   0.00 |    0.00 |    0.00 |    0.00 |    1.0 | ▇▁▁▁▁ |
| menarche       |          0 |              1 |   12.51 |   1.48 |   0.00 |   12.00 |   12.00 |   13.00 |   19.0 | ▁▁▂▇▁ |
| mheight        |          0 |              1 |   63.49 |   2.66 |  48.00 |   62.00 |   63.00 |   65.00 |   77.0 | ▁▁▇▂▁ |
| momage         |          0 |              1 |   20.30 |   3.88 |  12.00 |   18.00 |   20.00 |   22.00 |   44.0 | ▅▇▂▁▁ |
| mrace          |          0 |              1 |    1.63 |   0.77 |   1.00 |    1.00 |    2.00 |    2.00 |    4.0 | ▇▇▁▁▁ |
| parity         |          0 |              1 |    0.00 |   0.10 |   0.00 |    0.00 |    0.00 |    0.00 |    6.0 | ▇▁▁▁▁ |
| pnumlbw        |          0 |              1 |    0.00 |   0.00 |   0.00 |    0.00 |    0.00 |    0.00 |    0.0 | ▁▁▇▁▁ |
| pnumsga        |          0 |              1 |    0.00 |   0.00 |   0.00 |    0.00 |    0.00 |    0.00 |    0.0 | ▁▁▇▁▁ |
| ppbmi          |          0 |              1 |   21.57 |   3.18 |  13.07 |   19.53 |   21.03 |   22.91 |   46.1 | ▃▇▁▁▁ |
| ppwt           |          0 |              1 |  123.49 |  20.16 |  70.00 |  110.00 |  120.00 |  134.00 |  287.0 | ▅▇▁▁▁ |
| smoken         |          0 |              1 |    4.15 |   7.41 |   0.00 |    0.00 |    0.00 |    5.00 |   60.0 | ▇▁▁▁▁ |
| wtgain         |          0 |              1 |   22.08 |  10.94 | -46.00 |   15.00 |   22.00 |   28.00 |   89.0 | ▁▁▇▁▁ |

Looking into this data set, we can see that the total number of
observations is 4342 observations with 20 variables. The dataset
includes variables such as babysex, bhead, blength, bwt, delwt, fincome.
Additionally, all of the variables are numeric and there are no missing
values.

Next, we will convert numeric to factor variables.

``` r
birthweight = birthweight %>% 
  mutate(
    babysex = factor(babysex),
    babysex = fct_recode(babysex, "male" = '1', "female" = '2'),
    frace = factor(frace),
    frace = fct_recode(frace,
                       "White" = '1',
                       "Black" = '2',
                       "Asian" = '3',
                       "Puerto Rican" = '4',
                       "Other" = '8',
                       "Unknown" = '9'),
    malform = factor(malform),
    malform = fct_recode(malform,
                         "absent" = '0',
                         "present" = '1'),
    mrace = factor(mrace),
    mrace = fct_recode(mrace,
                       "White" = '1',
                       "Black" = '2',
                       "Asian" = '3',
                       "Puerto Rican" = '4',
                       "Other" = '8')
     )
```

#### My Model (Model 1)

Model 1: I will build my model using backwards selection, and validating
the predictors we are including using the current literature and my
hypotheses. For the backwards selection, we will start with a fully
saturated model, and then run backwards selection to remove all
non-significant predictors.

``` r
model1 = lm(bwt ~ ., data = birthweight) %>% 
  MASS::stepAIC(direction = "backward", trace = FALSE)

model1 %>% broom::tidy() %>% knitr::kable(digits = 3)
```

| term              |  estimate | std.error | statistic | p.value |
|:------------------|----------:|----------:|----------:|--------:|
| (Intercept)       | -6098.822 |   137.546 |   -44.340 |   0.000 |
| babysexfemale     |    28.558 |     8.455 |     3.378 |   0.001 |
| bhead             |   130.777 |     3.447 |    37.944 |   0.000 |
| blength           |    74.947 |     2.019 |    37.120 |   0.000 |
| delwt             |     4.107 |     0.392 |    10.475 |   0.000 |
| fincome           |     0.318 |     0.175 |     1.820 |   0.069 |
| gaweeks           |    11.592 |     1.462 |     7.929 |   0.000 |
| mheight           |     6.594 |     1.785 |     3.694 |   0.000 |
| mraceBlack        |  -138.792 |     9.907 |   -14.009 |   0.000 |
| mraceAsian        |   -74.887 |    42.315 |    -1.770 |   0.077 |
| mracePuerto Rican |  -100.678 |    19.325 |    -5.210 |   0.000 |
| parity            |    96.305 |    40.336 |     2.388 |   0.017 |
| ppwt              |    -2.676 |     0.427 |    -6.261 |   0.000 |
| smoken            |    -4.843 |     0.586 |    -8.271 |   0.000 |

Considering an alpha of 0.05 for significance, our model now contains
statistically significant predictors of baby’s birthweight, except for
fincome (family’s monthly income). To validate whether this predictor
should be included though it is not statistically significant, I looked
into the literature, and found that family income is positively
associated with baby’s birthweight, with lower incomes predicting lower
birthweights. This makes sense, as income can affect nutrition of the
mother during pregnancy and other social determinants of health.

I also looked at all of the significant predictors to ensure they are
variables used in the literature when looking at birth outcomes. Factors
relating to the mother such as maternal race and height, as well as
factors relating to the baby such as sex and length often appear in the
literature, so I feel comfortable including them. Additionally, the
literature shows that smoking during pregnancy can cause a lot of
malformations in children and can affect birthweight as well, so it
makes sense to include number of cigarettes smoked as a predictor.

Therefore, the predictors in my model (model 1) are sex of the baby,
head circumference, baby length, delivery weight, family income,
gestational age, mother’s height, mother’s race, parity, pre-pregnancy
weight, and number of cigarettes smoked.

#### Plot of model residuals against fitted values

``` r
add_residuals(birthweight, model1) %>% add_predictions(model1) %>% 
  ggplot(aes(x = resid, y = pred)) + geom_point(alpha = 0.5) +
  labs(x = "Predicted Birthweight (g)",
       y = "Residuals",
       title = "Relationship between Predicted Birthweight and Residuals")
```

![](p8105_hw6_sg3891_files/figure-gfm/resid_plot-1.png)<!-- -->

Looking at the comparison between predicted birthweight and the
residuals, we can see that there are some clear outliers, but the
majority of data has similar residual spread.

#### Additional Models and Cross Validation

Model with length at birth and gestational age as predictors

``` r
model2 = lm(bwt ~ 
              blength + gaweeks, 
              data = birthweight)
```

Model with head circumference, length, sex, and all interactions as
predictors

``` r
model3 = lm(bwt ~ 
              bhead + blength + babysex + 
              bhead * blength + bhead * babysex + blength * babysex + 
              bhead * blength * babysex, 
              data = birthweight)
```

In order to do the cross validation, we will first create the crossv\_mc
tibble with the train and test data

``` r
cv_df = crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )
```

Next, we will fit the models and get the root mean squared errors

``` r
fitted_df = cv_df %>%
  mutate(
    model1 = map(train, 
                 ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, 
                     data =.x)),
    model2 = map(train,
                  ~lm(bwt ~ blength + gaweeks, 
                     data = .x)),
    model3 = map(train,
                  ~lm(bwt ~ 
                      bhead + blength + babysex + 
                      bhead * blength + bhead * babysex +
                      blength * babysex +
                      bhead * blength * babysex,
                      data = .x))) %>% 
  mutate(
    rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
    rmse_model2  = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
    rmse_model3  = map2_dbl(model3, test, ~rmse(model = .x, data = .y))
)
```

Finally, we will plot the distribution of RMSE values to compare each
candidate model

``` r
fitted_df %>%
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin(alpha = 0.5) +
  labs(
    x = "Regression Model",
    y = "RSME",
    title = "Birthweight Regression Models and RSME values"
  )
```

![](p8105_hw6_sg3891_files/figure-gfm/rsme_plot-1.png)<!-- -->

From the plot above, we can see that the RSMEs are on average lowest for
model 1, then model 3, and finally model 2 has the highest RSME values.
This shows that model 1, the model that I have created using the
backwards selection and literature searches, is the best choice in terms
of prediction error, as it minimizes the average distance between the
actual birth weight and the predicted birthweight. The model that I have
selected includes no interaction terms, as opposed to model 3. The
predictors in my final model (model 1) are sex of the baby, head
circumference, baby length, delivery weight, family income, gestational
age, mother’s height, mother’s race, parity, pre-pregnancy weight, and
number of cigarettes smoked.

## Question 2

#### Load Weather Data

First, we will download the 2017 Central Park weather data

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

We will draw 5000 bootstrap samples and produce estimates of the
quantiles. We will work on a simple linear regression model, with tmax
as the outcome and tmin as the predictor.

#### R squared coefficient of determination

``` r
boot_straps_r_weather =
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm( tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>%
  select(-strap, -models) %>% 
  unnest(results)
  
boot_straps_r_weather %>% 
  janitor::clean_names() %>% 
  summarize(
    lower_limit = quantile(r_squared, c(.025)),
    upper_limit = quantile(r_squared, c(.975))) %>% 
  knitr::kable()
```

| lower\_limit | upper\_limit |
|-------------:|-------------:|
|    0.8936977 |    0.9274807 |

``` r
boot_straps_r_weather %>% 
  ggplot(aes(x = r.squared)) + 
  geom_density() +
  labs(
    x = "R Squared Values",
    y = "Density",
    title = "Distribution of R-Squared estimates for Central Park Weather"
  ) 
```

![](p8105_hw6_sg3891_files/figure-gfm/rsquared-1.png)<!-- --> We can see
that the distribution of the *r̂*<sup>2</sup> data is relatively normally
distributed, and is centered around 0.915. The 95% CI for the
*r̂*<sup>2</sup> values is (0.894, 0.927), as seen in the table above.

#### Log(B0\*B1)

``` r
boot_straps_log_weather =
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm( tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>%
  select(-strap, -models) %>% 
  unnest(results) %>% 
  janitor::clean_names() %>%
  select(id, term, estimate) %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) %>% 
  rename(intercept = '(Intercept)') %>% 
  mutate(log_b0b1 = log(intercept*tmin))

boot_straps_log_weather %>% 
  summarize(
    lower_limit = quantile(log_b0b1, c(.025)),
    upper_limit = quantile(log_b0b1, c(.975))) %>% 
  knitr::kable()
```

| lower\_limit | upper\_limit |
|-------------:|-------------:|
|     1.965633 |     2.058469 |

``` r
boot_straps_log_weather %>% 
  ggplot(aes(x = log_b0b1)) + 
  geom_density() +
  labs(
    x = "Log(B0*B1)",
    y = "Density",
    title = "Distribution of Log(B0*B1) estimates for Central Park Weather"
  ) 
```

![](p8105_hw6_sg3891_files/figure-gfm/logb0b1-1.png)<!-- -->

We can see that the distribution of the
log (*β̂*<sub>0</sub> \* *β̂*<sub>1</sub>) data is relatively normally
distributed, and is centered around 2.02 The 95% CI for the
log (*β̂*<sub>0</sub> \* *β̂*<sub>1</sub>) values is (1.966, 2.058), as
seen in the table above.
